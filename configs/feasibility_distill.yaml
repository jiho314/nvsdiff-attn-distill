# Distill 
distill_config:
  distill_pair_num: null # if not null, randomly select distill_pairs
  distill_pairs:  
    - [10, "point_map"]
  # student(unet)(down_blocks(6), mid_block(1), up_blocks(9)), teacher(vggt)(0~23, "track_head", "point_head")
  # unet: [64,64,32,32,16,16] [8] [16,16,16,32,32,32,64,64,64]
  distill_loss_weight:  # 0.05 per layer 
    - 0.01
  distill_loss_fn: 
    - "cross_entropy"  # "cross_entropy", "l1", ...
  
  unet_query_head:
    - "n_interpolate2d_deepconv2d"  # "identity", "mlp", "deepconv2d", "interpolate2d_deepconv2d", "n_interpolate2d_deepconv2d"
  unet_query_head_kwargs: 
    - { "block_num": 1, 
        "block_kwargs_list": [
            # {"upsample_size": 64, "mid_dim":64, "out_dim": 32, "depth": 1, "last_activation" : 'gelu',"use_batchnorm": false },
            {"upsample_size": 64, "mid_dim":64, "out_dim": 16,  "depth": 7, "last_activation" : null, "use_batchnorm": false }]
      }
  unet_key_head:
    - "n_interpolate2d_deepconv2d"  # "softmax_headmean", "identity", "softmax_headmlp"
  unet_key_head_kwargs: 
    - {
        "block_num": 1, 
        "block_kwargs_list": [
            # {"upsample_size": 64, "mid_dim":64, "out_dim": 32, "depth": 2, "last_activation" : 'gelu',"use_batchnorm": false },
            {"upsample_size": 64, "mid_dim":64, "out_dim": 16,  "depth": 7, "last_activation" : null, "use_batchnorm": false }
        ]
      }
  unet_logit_head: 
    - "HeadMlp_Softmax"  # "softmax_headmean", "identity", "softmax_headmlp"
  unet_logit_head_kwargs: 
    - {"per_view": True, "softmax_temp": 1.0, "learnable_temp": false, "mlp_ratio":0, "mlp_depth": 0}
  vggt_logit_head: 
    - "softmax_headmean"  # "softmax_headmean", "identity", "softmax_headmlp"
  vggt_logit_head_kwargs: 
    - {"per_view": True, "softmax_temp": 0.1}
  
  cost_metric: 
    - "neg_l2" # "dot_product", "neg_l2", "neg_log_l2", "inverse_l2"

  distill_key_for_reference_query: 
    - ["reference", "target"] # ["reference", "target", "self"] 
  distill_key_for_target_query: 
    - [ "reference", "target" ] # ["reference", "target", "self"]

  save_vram_query_axis: false # randomly select distill query for vram, if False: both used

  # (consistency) masking option
  mask_per_view_consistency: 
    - True
  mask_full_view_consistency:
    - False

  consistency_check: 
    - True
  consistency_check_cfg:
    - pixel_threshold: 1.5

  learning_rate : 1e-4
  distill_loss_weight_scheduling: null # "cosine"
  distill_loss_weight_scheduling_config: 
    # start_w: 0.04
    # end_w: 0.005
    # end_step: 10000



dino_on_fly: false
# vggt
vggt_on_fly : false
use_vggt_camera : false

nframe: 3
fix_cond_num: 1
min_cond_num: null
max_cond_num: null

# eval: 20 -> 6 min / 4gpu = 1.5min
val_nframe: 3
val_cond_num: 1
val_compute_fid: false
val_viz_len: 15

train_batch_size: 1 # Batch size (per device) for the training dataloader，必须是n_frames_per_seq的倍数
shuffle_train_rate: 0.5 # the rate to shuffle frames in training dataset

train_timestep_schedule: "uniform" # "uniform" or "gaussian"
# train_timestep_schedule_config:
#   mean: 1000
#   std: 200

train_dataset:
  cls_name: multi_wds
  config:
    url_paths:
    - /mnt/data2/minseop/co3d_wds_val/unseen_scene
    dataset_length: 1600
    resampled: true
    shardshuffle: true
    shuffle_buffer_size: 200
    re10k_process_kwargs:
      min_view_range: null
      max_view_range: null
    co3d_process_kwargs:
      min_view_range: 4
      max_view_range: 4

val_datasets:
  co3d_val_subset_unseen_scene:
    cls_name: co3d_wds
    config:
      url_paths: 
       - /mnt/data2/minseop/co3d_wds_val_subset/unseen_scene
      dataset_length: 75
      resampled: false
      shardshuffle: false
      inference: true
      inference_view_range: 4
      process_kwargs:
        get_square_extrinsic: true
  co3d_val_subset_unseen_category:
    cls_name: co3d_wds
    config:
      url_paths: 
       - /mnt/data2/minseop/co3d_wds_val_subset/unseen_category
      dataset_length: 25
      resampled: false
      shardshuffle: false
      inference: true
      inference_view_range: 4
      process_kwargs:
        get_square_extrinsic: true


# test_dataset_cls: build_re10k_wds # build_re10k_wds lvsm_dataset
# test_dataset_config:



# pretrained_model_name_or_path: "./check_points/models--stabilityai--stable-diffusion-2-1-base/snapshots/5ede9e4bf3e3fd1cb0ef2f7a3fff13ee514fdf06"
pretrained_model_name_or_path: "stabilityai/stable-diffusion-2-1"


image_size: 512
gradient_accumulation_steps: 1 # Number of updates steps to accumulate before performing a backward/update pass.
gradient_checkpointing: True
allow_tf32: False # Whether or not to allow TF32 on Ampere GPUs. Can be used to speed up training.
dataloader_num_workers: 8
max_train_steps: 400000 # Total number of training steps to perform.  If provided, overrides num_train_epochs.
num_train_epochs: 1500
checkpointing_steps_manual: []
checkpointing_steps: 10000 # Save a checkpoint of the training state every X updates.
checkpoints_total_limit: -1 # -1
validation_epochs: 10 # Run validation every X epochs.

# The prediction_type that shall be used for training. Choose between 'epsilon' or 'v_prediction' or leave `None`.
# If left to `None` the default prediction type of the scheduler: `noise_scheduler.config.prediciton_type` is chosen.
prediction_type: null
use_ema: False # Whether to use EMA model.
enable_xformers_memory_efficient_attention: False # torch>=2.0已经支持了flashattention2
noise_offset: 0.0 # The scale of noise offset.
input_perturbation: 0.0 # The scale of input perturbation. Recommended 0.1.

# scheduler params
rescale_betas_zero_snr: True
beta_schedule: "snr_rescale" # scaled_linear, linear, snr_rescale, snr_rescale2
# 多数据集平均SNR^2: [3.76, 4.98, 6.41, 8.05]
snr_rescale: 4 # snr_rescale(2) needs sqrt
adaptive_betas: False # if this is true, beta_schedule must be scaled linear
dyn_scheduler: False
tag_dict: { # jiho TODO: 이게 뭐여
  "co3dv2": [2.84011065, 3.48885126, 4.35105637, 5.25987238],
  "mvimagenet": [3.48130056, 4.61248985, 5.81117017, 7.34165587],
  "dl3dv": [5.48732045, 7.71244067, 10.5128295, 13.44243126],
  "real10k": [4.96658347, 6.83804047, 8.88339281, 11.38805201],
  "scannet++": [2.49597564, 3.07893548, 3.77435998, 4.59721609],
  "objaverse": [4.80551779, 6.67680627, 8.88053301, 11.43800651],
  "gl3d": [4.71029608, 6.35166526, 8.07183511, 10.18783744]
}
match_scheduler: False
max_overlap: 0.75


multi_scale: null # Not Used(only used for data sampler)

# camera params
# camera_longest_side: null # null, 5.0 # not used
normalize_extrinsic: True # relative camera pose
normalize_t: False # it should be false, if camera_longest_side is not None
fourier_embedding: False
fourier_embed_dim: 18

model_cfg:
  cfg_training_rate: 0.1
  coords_cfg: null # 0.15
  enable_depth: False
  align_depth: False
  priors3d: False
  prior_type: null # 3dpe (coord_dim=192), latent, warp_latent (coord_dim=4), 3dpe+pixel (coord_dim=192, add_in_ch=11), 3dpe+latent or 3dpe+warp_latent (coord_dim=192+4=196)
  coord_dim: null
  depth_mid_times: null # 计算depth中位数，超出中位数*N倍的depth将会被contract截断
  coord_encoder: null # "conv_in" is used for conv inputs, "attn_in" is used before qk-dot in global attn, "cross_in" is used for cross-attention injection
  coord_dropout: null # null
  coord_downsample_type: null # "conv", "resize"
  use_rope: False
  depth_freq: null # 32
  additional_in_channels: 7 # (mask 1, camera 6, depth 1~x) # 7, [7, 54], 8
  no_text_cross_attn: True # True
  qk_norm: True
  # domain switcher
  # domain_dict: {"others": 0, "megascenes": 1, "objaverse": 2}
  domain_dict: null
  class_embed_type: "zero_init"
  num_class_embeds: 3

opt_cfg:
  learning_rate: 2.5e-5 # 5.0e-5 # Initial learning rate (after the potential warmup period) to use.
  scale_lr_base_batch_size: null # include frame num(8 scenes *16gpus (64=8scenes x 8frames))
  scale_lr: False # Scale the learning rate by the number of GPUs, gradient accumulation steps, and batch size.
  lr_scheduler: "constant_with_warmup" # ["linear", "cosine", "cosine_with_restarts", "polynomial", "constant", "constant_with_warmup"]
  lr_warmup_steps: 500 # Number of steps for the warmup in the lr scheduler.
  snr_gamma: null # 'None' means constant 1. SNR weighting gamma to be used if rebalancing the loss. Recommended value is 5.0.
  use_8bit_adam: False

  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_weight_decay: 0.01
  adam_epsilon: 1.0e-8
  max_grad_norm: 1.0
